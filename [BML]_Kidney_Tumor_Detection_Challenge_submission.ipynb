{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "[BML] Kidney Tumor Detection Challenge - submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rydybwXAOGb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-rIwPIMjiaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from starter_code.utils import load_case, load_volume\n",
        "from starter_code.visualize import visualize\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import sys\n",
        " \n",
        "import numpy as np\n",
        " \n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        " \n",
        "from skimage.io import imread, imshow\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldS02auZ-SRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip 'drive/My Drive/data.zip' # this folder contains all the train and test data\n",
        "!unzip 'drive/My Drive/starter_code.zip' # this folder contains all the code to manipulate the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP-MFbkAzOxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data # we move data to a folder stored on the disk\n",
        "!mv -f case** data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XPsp6_r9t0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 512\n",
        "IMG_CHANNELS = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P71XfRQ0jiay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function build a model that got inspired by the U-Net architecture.\n",
        "\n",
        "def build_model():\n",
        "    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(s)\n",
        "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c1)\n",
        "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(p1)\n",
        "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c2)\n",
        "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(p2)\n",
        "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c3)\n",
        "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(p3)\n",
        "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c4)\n",
        "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(p4)\n",
        "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c5)\n",
        "\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(u6)\n",
        "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c6)\n",
        "\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(u7)\n",
        "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c7)\n",
        "\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(u8)\n",
        "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c8)\n",
        "\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(u9)\n",
        "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
        "                                padding='same')(c9)\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(3, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mubecq1K-EIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we build the model and compile it\n",
        "\n",
        "model = build_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRjm4V6nAnbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data preprocessing and training\n",
        "\n",
        "for o in range(0, 210, 10):\n",
        "  if o != 0:\n",
        "    model = load_model(\"drive/My Drive/model.h5\")\n",
        "\n",
        "  X = None\n",
        "  Y = None\n",
        "\n",
        "  for i in range(o, o + 5):\n",
        "      volume, segmentation = load_case(i)\n",
        "      try:\n",
        "          data_v = volume.get_fdata()          # we extract corresponding numpy array data\n",
        "          data_s = segmentation.get_fdata()\n",
        "          if X is None:\n",
        "              X = data_v\n",
        "              Y = data_s\n",
        "          else:\n",
        "              X = np.concatenate([X, data_v])\n",
        "              Y = np.concatenate([Y, data_s])\n",
        "      except:\n",
        "          print(i)\n",
        "      if i % 5 == 0:\n",
        "          print(i)\n",
        "\n",
        "      X = X.reshape((X.shape[0], 512, 512, 1))\n",
        "      # One hot encoding of Y\n",
        "      Y = to_categorical(Y, 3)\n",
        "\n",
        "      checkpoint_path = \"drive/My Drive/cp1.ckpt\"\n",
        "      checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "      \n",
        "      # Create checkpoint callback\n",
        "      cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                      save_weights_only=True,\n",
        "                                                      verbose=1)\n",
        "      \n",
        "      callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
        "        tf.keras.callbacks.TensorBoard(log_dir='./logs', profile_batch=100000000),\n",
        "        cp_callback \n",
        "      ]\n",
        "\n",
        "      # We fit the model to the data\n",
        "      history = model.fit(X, Y, validation_split=0.15, batch_size=32, epochs=20, verbose=1)\n",
        "      model.save(\"drive/My Drive/model.h5\")\n",
        "\n",
        "      # Plot training & validation accuracy values\n",
        "      plt.plot(history.history['acc'])\n",
        "      plt.plot(history.history['val_acc'])\n",
        "      plt.title('Model accuracy')\n",
        "      plt.ylabel('Accuracy')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.show()\n",
        "\n",
        "      # Plot training & validation loss values\n",
        "      plt.plot(history.history['loss'])\n",
        "      plt.plot(history.history['val_loss'])\n",
        "      plt.title('Model loss')\n",
        "      plt.ylabel('Loss')\n",
        "      plt.xlabel('Epoch')\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXUf4n1aDYMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function applies a one hot decode to a given prediction\n",
        "\n",
        "def onehot_decode(X):\n",
        "  res = np.empty((X.shape[0], X.shape[1], X.shape[2]))\n",
        "  for x in range(X.shape[0]):\n",
        "    for y in range(X.shape[1]):\n",
        "        res[x][y] = np.argmax(X[x][y], axis=1)\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvwgBDH72A1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model(\"drive/My Drive/model.h5\")  # We load our saved model\n",
        "\n",
        "for i in range(200, 300):\n",
        "  volume = load_volume(i)  # We load test image\n",
        "  try:\n",
        "    affine = volume.affine\n",
        "    X = volume.get_fdata()\n",
        "    X = X.reshape((X.shape[0], 512, 512, 1))\n",
        "    X_pred = model.predict(X)   # We feed it to our neural network to get the prediction\n",
        "\n",
        "    res = onehot_decode(X_pred)  # One hot decode + reconstruction of a new NIFTI Image\n",
        "    img = nib.Nifti1Image(res, affine)\n",
        "    os.mkdir(\"drive/My Drive/results/\" + \"case_{:05d}\".format(i))\n",
        "\n",
        "    os.system(\"touch drive/My Drive/results/\" + \"case_{:05d}\".format(i) +\"/segmentation.nii\")\n",
        "    img.to_filename(\"drive/My Drive/results/\" + \"case_{:05d}\".format(i) +\"/segmentation.nii\")\n",
        "  except Exception as e:\n",
        "    print(\"issue {} {}\".format(e, i))\n",
        "  \n",
        "  if i % 5 == 0:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}